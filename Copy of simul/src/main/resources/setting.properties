#kafka, aggregator
#simulator.type=collectd
simulator.type=collectd

#common-config
simulator.thread.size=2
simulator.filepath=D:\collectd.log
simulator.interval=10
simulator.enablehostname=disable
simulator.hostname=helloworld
simulator.startnum=2

#log
log.path=D:/
log.fileSize=2GB
log.name=simulLog.log
log.level=debug

#collectd-config (prefix = metric) - defalut value size 4
#collectd.cpu.idle=123123, 1231232, 123123, 12345
test.config.value=4
test.cpu.system=1,2,3,4
test.cpu.user=123,123,123,123
test.cpu.idle=123,123,123,123
test.memory.used=123,123,123,123
#df - value
test.df.partition=/root,/app/root,/rex
test.df.free=1,2,3,4,5,6,7,8,9,10,11,12
test.df.used=1,2,3,4,5,6,7,8,9,10,11,12

#aggregator config (prefix = aggregator)
aggregator.ip=localhost
aggregator.port=8088

#kafka producer config (prefix = producer)
producer.topic=resource-collectd
#producer.bootstrap.servers=192.168.80.128:9092, 192.168.80.128:9093, 192.168.80.128:9094
producer.bootstrap.servers=10.202.142.145:9092, 10.202.142.146:9092, 10.202.142.147:9092
producer.acks=all
producer.retries=0
producer.retry.backoff.ms=200
producer.batch.size=16384
producer.linger.ms=0
producer.buffer.memory=33554432
producer.max.block.ms=60000
producer.send.buffer.bytes=131072
producer.key.serializer=org.apache.kafka.common.serialization.StringSerializer
producer.value.serializer=org.apache.kafka.common.serialization.StringSerializer