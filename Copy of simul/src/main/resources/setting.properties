#kafka, aggregator
#simulator.type=collectd
simulator.type=collectdwin

#common-config
simulator.thread.size=1
simulator.filepath=D:\collectd.log
simulator.interval=10000
simulator.enablehostname=disable
simulator.hostname=test
simulator.startnum=0

#log
log.path=
log.size=
log.name=
log.level=

#collectd-config (prefix = metric) - defalut value size 4
#collectd.cpu.idle=123123, 1231232, 123123, 12345
test.config.value=4
test.cpu.system=1,2,3,4
test.cpu.user=123,123,123,123
test.cpu.idle=123,123,123,123
test.memory.used=123,123,123,123
test.df.partition=root/config,root,etc
test.df.free=123,123,123,123,123
test.df.used=123,123,123,123,123

#aggregator config (prefix = aggregator)
aggregator.ip=192.168.80.128
aggregator.port=28080

#kafka producer config (prefix = producer)
producer.topic=resource-collectd
producer.bootstrap.servers=192.168.80.128:9092, 192.168.80.128:9093, 192.168.80.128:9094
#bootstrap.servers=10.202.142.145:9092, 10.202.142.146:9092, 10.202.142.147:9094
producer.acks=all
producer.retries=0
producer.retry.backoff.ms=200
producer.batch.size=16384
producer.linger.ms=0
producer.buffer.memory=33554432
producer.max.block.ms=60000
producer.send.buffer.bytes=131072
producer.key.serializer=org.apache.kafka.common.serialization.StringSerializer
producer.value.serializer=org.apache.kafka.common.serialization.StringSerializer